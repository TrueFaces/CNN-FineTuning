{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "600f7afd",
   "metadata": {},
   "source": [
    "## Preprocesamiento:  \n",
    "\n",
    "Este código carga imágenes de dos carpetas diferentes (\"Datanoface\" y \"Dataface\"), las redimensiona a un tamaño determinado, las normaliza y las etiqueta según la carpeta de origen. Luego divide los datos y las etiquetas en tres conjuntos: un conjunto de prueba, un conjunto de entrenamiento y un conjunto de validación. Finalmente, devuelve los seis conjuntos de datos y etiquetas en variables separadas: X_test, y_test, X_train, y_train, X_val y y_val.  \n",
    "\n",
    "En resumen, este código se utiliza para cargar, procesar y dividir un conjunto de imágenes en tres conjuntos diferentes para entrenar, validar y evaluar modelos de aprendizaje automático o de visión por computadora.\n",
    "\n",
    "\n",
    "## Datos\n",
    "\n",
    "Fotos con rostro: 202.999 imagenes.\n",
    "Fotos sin rostro: 32.461 imagenes.\n",
    "\n",
    "\n",
    "\n",
    "## La arquitectura de este modelo es la siguiente:  \n",
    "\n",
    "Se carga el modelo pre-entrenado VGG16 sin la capa superior (include_top=False) y se congela su pesos para que no se actualicen durante el entrenamiento.  \n",
    "\n",
    "Se agrega una nueva capa superior al modelo para la clasificación binaria. Primero se aplana la salida de la base del modelo usando la capa Flatten(). Luego se agrega una capa Dense de 128 unidades con función de activación relu, seguida de una capa de salida Dense con una única unidad y función de activación sigmoid.  \n",
    "\n",
    "Se compila el modelo con la función de pérdida binary_crossentropy, el optimizador Adam y la métrica de precisión (accuracy).  \n",
    "\n",
    "Finalmente, se entrena el modelo durante 15 épocas con un tamaño de lote (batch size) de 100 y se utiliza EarlyStopping para prevenir el sobreajuste. Después, se evalúa el modelo en el conjunto de pruebas.\n",
    "    \n",
    "## Pruebas  \n",
    "La función llamada \"predecir_con_modelo\" se utiliza en el  modelo de aprendizaje  para hacer predicciones sobre la presencia de caras en imágenes. La función toma dos argumentos: el modelo y la ruta de la carpeta que contiene las imágenes que se van a analizar.\n",
    "\n",
    "La función utiliza un bucle \"for\" para recorrer cada imagen en la carpeta. Para cada imagen, se carga la imagen utilizando la librería OpenCV, se realiza el preprocesamiento (cambio de tamaño y normalización) y se utiliza el modelo para hacer una predicción sobre si hay o no una cara en la imagen.\n",
    "\n",
    "Si la predicción es mayor a 0.01, la función muestra un mensaje indicando que hay una cara en la imagen, de lo contrario muestra un mensaje indicando que no hay una cara en la imagen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b49f9d3d-dde1-4274-b51a-93e8a4178107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: .\\Datanoface\\noface\\ILSVRC2012_val_00013491.JPEG\n",
      "Failed to load image: .\\Datanoface\\noface\\ILSVRC2012_val_00028437.JPEG\n",
      "Loaded 235458 images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def etiquetar_imagenes(folder1, folder2, img_size=100, test_size=0.2):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for category in os.listdir(folder1):\n",
    "        path = os.path.join(folder1, category)\n",
    "        if os.path.isdir(path):\n",
    "            for img_name in os.listdir(path):\n",
    "                img_path = os.path.join(path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB color space\n",
    "                    img = cv2.resize(img, (img_size, img_size))\n",
    "                    img = img.astype('float32') / 255.0  # Normalize the image\n",
    "                    data.append(img)\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    print(f\"Failed to load image: {img_path}\")\n",
    "\n",
    "    for category in os.listdir(folder2):\n",
    "        path = os.path.join(folder2, category)\n",
    "        if os.path.isdir(path):\n",
    "            for img_name in os.listdir(path):\n",
    "                img_path = os.path.join(path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB color space\n",
    "                    img = cv2.resize(img, (img_size, img_size))\n",
    "                    img = img.astype('float32') / 255.0  # Normalize the image\n",
    "                    data.append(img)\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    print(f\"Failed to load image: {img_path}\")\n",
    "\n",
    "    data = np.array(data).reshape(-1, img_size, img_size, 3)  # Reshape to 4D array\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(f\"Loaded {len(data)} images.\")\n",
    "    \n",
    "    # Split the data and labels into training and validation sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(data, labels, test_size=test_size, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=test_size, random_state=42)\n",
    "\n",
    "    return X_test, y_test, X_train, y_train, X_val, y_val\n",
    "\n",
    "X_test, y_test, X_train, y_train, X_val, y_val = etiquetar_imagenes(r\".\\Datanoface\", r\".\\Dataface\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d02d3cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8aa9812-1de2-428a-8292-56e98ec1c092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,304,769\n",
      "Trainable params: 590,081\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1507/1507 [==============================] - 2905s 2s/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.0157 - val_accuracy: 0.9950\n",
      "Epoch 2/15\n",
      "1507/1507 [==============================] - 3127s 2s/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.0152 - val_accuracy: 0.9952\n",
      "Epoch 3/15\n",
      "1507/1507 [==============================] - 5200s 3s/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0140 - val_accuracy: 0.9956\n",
      "Epoch 4/15\n",
      "1507/1507 [==============================] - 5199s 3s/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0157 - val_accuracy: 0.9952\n",
      "Epoch 5/15\n",
      "1507/1507 [==============================] - 5199s 3s/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0154 - val_accuracy: 0.9951\n",
      "Epoch 6/15\n",
      "1507/1507 [==============================] - 5196s 3s/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0164 - val_accuracy: 0.9955\n",
      "Epoch 6: early stopping\n",
      "1472/1472 [==============================] - 1331s 904ms/step - loss: 0.0143 - accuracy: 0.9963\n",
      "Test accuracy: 0.9962838888168335\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import patlib\n",
    "import os\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Dropout,Activation,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top layer (include_top=False)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
    "\n",
    "# Freeze the weights of the pre-trained layers so they are not updated during training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a new top layer to the model for binary classification\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "# Train the model for 10 epochs with a batch size of 32\n",
    "H=model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=15, batch_size=100,callbacks=[early_stop])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "103636b6-bd70-4085-85a7-b7f0c89a2aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('modeloVGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c5f6932-ee3a-4166-847e-545b14d0a06a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def predecir_con_modelo(modelo, folder_path):\n",
    "    # Recorrer todas las imágenes en la carpeta\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        # Cargar la imagen y hacer la preprocesamiento\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir a espacio de color RGB\n",
    "        img = cv2.resize(img, (100, 100))  # Cambiar el tamaño a 100x100 píxeles\n",
    "        img = img.astype('float32') / 255.0  # Normalizar la imagen\n",
    "\n",
    "        # Hacer la predicción\n",
    "        pred = modelo.predict(np.array([img]))\n",
    "        if pred[0][0] > 0.01:\n",
    "            print(filename, \"Sí hay una cara en la imagen.\")\n",
    "        else:\n",
    "            print(filename, \"No hay una cara en la imagen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f504598-a866-4cfe-9f37-79f67dc62974",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 802ms/step\n",
      "FACE1.jpg Sí hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 790ms/step\n",
      "FACE2.jpg Sí hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 792ms/step\n",
      "FACE3.jpg Sí hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 785ms/step\n",
      "FACE4.jpg Sí hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 783ms/step\n",
      "FACE5.jpg Sí hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 796ms/step\n",
      "FACE6.jpg Sí hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 796ms/step\n",
      "FACE7.jpg Sí hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 795ms/step\n",
      "FACE8.jpg No hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 792ms/step\n",
      "FACE9.jpg Sí hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 791ms/step\n",
      "NOFACE.jpg No hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 792ms/step\n",
      "NOFACE1.jpg No hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 805ms/step\n",
      "NOFACE2.jpg No hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 797ms/step\n",
      "NOFACE3.jpg No hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 792ms/step\n",
      "NOFACE4.jpg No hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 786ms/step\n",
      "NOFACE5.jpg No hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 791ms/step\n",
      "NOFACE6.jpg No hay una cara en la imagen.\n",
      "1/1 [==============================] - 1s 786ms/step\n",
      "NOFACE7.jpg No hay una cara en la imagen.\n"
     ]
    }
   ],
   "source": [
    "predecir_con_modelo(model, './fotos/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae62cf-788f-4dec-bb63-5c456af48747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
