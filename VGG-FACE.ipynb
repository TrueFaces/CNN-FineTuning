{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14c0fc85-2703-4397-b882-dd3a316498f2",
   "metadata": {},
   "source": [
    "# Reconocimiento de caras con Keras usando una VGG Face. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a6085-d1f7-4fc7-8b9e-278a3aedb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este codigo nos permite comparar imagenes con caras y determinar si son de la misma persona o no.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a38ebc6-c857-4eeb-97dc-2f6ec6846bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26365d3-ff02-4510-8ad5-d0f50f973248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433c53ba-9716-4dd1-8eb6-4d12a1df8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necesarios\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import misc, ndimage\n",
    "from keras import Model\n",
    "from keras import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "\n",
    "# La imagen hay que procesarla para adaptarla a la red VGG-FACE\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    " \n",
    "# DEFINIMOS el modelo de la VGG-FACE\n",
    "    \n",
    "def prepare_model():\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "     \n",
    "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "# Cargamos los pesos de la VGG-FACE\n",
    "\n",
    "    model.load_weights('vgg_face_weights.h5')\n",
    "    \n",
    "# Modificamos el clasificador anulando las dos ultimas capas lo que nos devolvera un vector\n",
    "#que podra ser comparado con otros vectores (imagenes) utilizando para ello\n",
    "#la metrica similitud de coseno\n",
    "\n",
    "    vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n",
    "    return vgg_face_descriptor\n",
    "\n",
    "\n",
    "# Funcion que devuelve la simitud entre dos imagenes.\n",
    "\n",
    "\n",
    "\n",
    "def same_person(model, img1, img2):\n",
    "    img1_representation = model.predict(preprocess_image(img1))[0,:]\n",
    "    img2_representation = model.predict(preprocess_image(img2))[0,:]\n",
    "\n",
    "    a = np.matmul(np.transpose(img1_representation), img2_representation)\n",
    "    b = np.sum(np.multiply(img1_representation, img1_representation))\n",
    "    c = np.sum(np.multiply(img2_representation, img2_representation))\n",
    "    cosine_similarity = 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "    print(cosine_similarity)\n",
    "\n",
    "    if cosine_similarity < 0.4:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "model = prepare_model()\n",
    "\n",
    "# Esta funcion debera ser modificada y hacer otra si lo que pretendemos es tomar\n",
    "# una foto como referencia , que sea comparada con el esto de fotos de un album, carpeta,etc y se retorne todas aquellas fotos \n",
    "#que pertenezcan a la foto de referencia\n",
    "\n",
    "# Crear funcion: \n",
    "\n",
    "if same_person(model, 'bengio1.jpg', 'bengio2.jpg'):\n",
    "    print(\"Same person!\")\n",
    "else:\n",
    "    print(\":(\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
